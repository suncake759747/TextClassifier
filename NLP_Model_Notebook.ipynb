{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's Get Started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In case you're having trouble with keras / tensorflow issues, enable (top dropdown menu) following cell and run"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import some standard stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import config\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import some custom stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras_model_helpers import build_keras_model, use_lstm\n",
    "from nb_model_helpers import build_nb_model, use_nb\n",
    "from util import split_data\n",
    "from vocabulary_processor_helpers import build_vocabulary_processor, _text_normalizer, _tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file_name = 'case_study_data.csv' # change as desired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Data. Please Wait!\n"
     ]
    }
   ],
   "source": [
    "label_mapping, total_training_samples, total_validation_samples, total_test_samples = split_data(data_file_name)\n",
    "train_steps = int(math.ceil(total_training_samples / config.batch_size))\n",
    "validation_steps = int(math.ceil(total_validation_samples / config.batch_size))\n",
    "\n",
    "with open('label_mapping_dict.p', 'wb') as f:\n",
    "    pickle.dump(label_mapping, f)\n",
    "reverse_label_mapping = dict((x[1], x[0]) for x in label_mapping.items())\n",
    "with open('reverse_label_mapping_dict.p', 'wb') as f:\n",
    "    pickle.dump(reverse_label_mapping, f)\n",
    "    \n",
    "data_root = 'data/'\n",
    "validation_data_path = os.path.join(data_root, 'validation_data.tsv')\n",
    "test_data_path = os.path.join(data_root, 'test_data.tsv')\n",
    "training_data_path = os.path.join(data_root, 'training_data.tsv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building a Naive Bayes model\n",
      "Processing Training Data\n",
      "Processing Validation Data\n",
      "Processing Test Data\n",
      "Confusion Matrix for VALIDATION data in data/validation_data.tsv\n",
      "PREDICTED CLASS ON X-AXIS. TRUE CLASS ON Y-AXIS.\n",
      "                  bank_service  credit_card  credit_reporting  \\\n",
      "bank_service              1549          252                36   \n",
      "credit_card                138         2409               171   \n",
      "credit_reporting            33          244              7110   \n",
      "debt_collection             26          132               439   \n",
      "loan                        41           72               186   \n",
      "money_transfers            138           58                 0   \n",
      "mortgage                    29           24                45   \n",
      "\n",
      "                  debt_collection  loan  money_transfers  mortgage  \n",
      "bank_service                   28    21               18       103  \n",
      "credit_card                   114    77               12        34  \n",
      "credit_reporting              448   168                0       120  \n",
      "debt_collection              5147   277                2       125  \n",
      "loan                          264  2405                1       135  \n",
      "money_transfers                 2     8              256        11  \n",
      "mortgage                       52    38                0      3839  \n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    bank_service       0.79      0.77      0.78      2007\n",
      "     credit_card       0.75      0.82      0.78      2955\n",
      "credit_reporting       0.89      0.88      0.88      8123\n",
      " debt_collection       0.85      0.84      0.84      6148\n",
      "            loan       0.80      0.77      0.79      3104\n",
      " money_transfers       0.89      0.54      0.67       473\n",
      "        mortgage       0.88      0.95      0.91      4027\n",
      "\n",
      "       micro avg       0.85      0.85      0.85     26837\n",
      "       macro avg       0.84      0.80      0.81     26837\n",
      "    weighted avg       0.85      0.85      0.85     26837\n",
      "\n",
      "Confusion Matrix for TEST data in data/test_data.tsv\n",
      "PREDICTED CLASS ON X-AXIS. TRUE CLASS ON Y-AXIS.\n",
      "                  bank_service  credit_card  credit_reporting  \\\n",
      "bank_service              1567          218                44   \n",
      "credit_card                131         2369               190   \n",
      "credit_reporting            29          251              7094   \n",
      "debt_collection             38          155               478   \n",
      "loan                        42           82               169   \n",
      "money_transfers            139           44                 0   \n",
      "mortgage                    20           24                79   \n",
      "\n",
      "                  debt_collection  loan  money_transfers  mortgage  \n",
      "bank_service                   19    32               20       107  \n",
      "credit_card                   146    73                2        44  \n",
      "credit_reporting              457   170                1       121  \n",
      "debt_collection              5097   249                3       127  \n",
      "loan                          263  2434                1       112  \n",
      "money_transfers                10     8              263        10  \n",
      "mortgage                       52    33                0      3819  \n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    bank_service       0.80      0.78      0.79      2007\n",
      "     credit_card       0.75      0.80      0.78      2955\n",
      "credit_reporting       0.88      0.87      0.88      8123\n",
      " debt_collection       0.84      0.83      0.84      6147\n",
      "            loan       0.81      0.78      0.80      3103\n",
      " money_transfers       0.91      0.55      0.69       474\n",
      "        mortgage       0.88      0.95      0.91      4027\n",
      "\n",
      "       micro avg       0.84      0.84      0.84     26836\n",
      "       macro avg       0.84      0.80      0.81     26836\n",
      "    weighted avg       0.84      0.84      0.84     26836\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Building a Naive Bayes model\")\n",
    "nb_model = build_nb_model(training_data_path, test_data_path, validation_data_path)\n",
    "nb_probs, true_classes, nb_preds, ids = use_nb(test_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building an LSTM model\n",
      "Model built with vocabulary of size 25810\n",
      "Epoch 1/2\n",
      " 840/3355 [======>.......................] - ETA: 47:29 - loss: 0.8813 - acc: 0.7000"
     ]
    }
   ],
   "source": [
    "print(\"Building an LSTM model\")\n",
    "vocab_processor = build_vocabulary_processor(training_data_path, config.max_len, config.min_word_count_freq)\n",
    "with open('vocab_processor.p', 'wb') as f:\n",
    "    pickle.dump(vocab_processor, f)\n",
    "    \n",
    "model = build_keras_model(config.batch_size, config.dropout_rate, config.embedding_size, config.max_len, \n",
    "                          config.num_epochs, train_steps, validation_steps, vocab_processor, label_mapping,\n",
    "                          training_data_path, validation_data_path, model_name='saved_keras_model')\n",
    "\n",
    "lstm_probs, true_classes, lstm_preds, ids = use_lstm(model, test_data_path, vocab_processor, label_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Can score new datasets and have redicted sample labels will written to tsv files\n",
    "### Assumes new dataset is in same format as original dataset (case_study_data.csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Change 'dataset_that_you_want_to_score' to the name of your dataset file (should contain same columns/headers/labels as case_study_data.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python use_trained_nb_model.py dataset_that_you_want_score.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python use_trained_lstm_model.py dataset_that_you_want_score.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
